{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN707z42PujvMKATay96R+N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vhtt31jzUIND","executionInfo":{"status":"ok","timestamp":1761783851700,"user_tz":180,"elapsed":600,"user":{"displayName":"Ana Julia Alves","userId":"11391275543141261359"}},"outputId":"2feaadb9-8cc6-462c-89cb-0c15f7195ed0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Época [10/100], Loss: 0.6023\n","Época [20/100], Loss: 0.5937\n","Época [30/100], Loss: 0.5889\n","Época [40/100], Loss: 0.5859\n","Época [50/100], Loss: 0.5836\n","Época [60/100], Loss: 0.5817\n","Época [70/100], Loss: 0.5801\n","Época [80/100], Loss: 0.5786\n","Época [90/100], Loss: 0.5771\n","Época [100/100], Loss: 0.5757\n","Época [110/100], Loss: 0.5744\n","Época [120/100], Loss: 0.5731\n","Época [130/100], Loss: 0.5718\n","Época [140/100], Loss: 0.5706\n","Época [150/100], Loss: 0.5694\n","Época [160/100], Loss: 0.5683\n","Época [170/100], Loss: 0.5672\n","Época [180/100], Loss: 0.5661\n","Época [190/100], Loss: 0.5650\n","Época [200/100], Loss: 0.5640\n","Época [210/100], Loss: 0.5629\n","Época [220/100], Loss: 0.5620\n","Época [230/100], Loss: 0.5610\n","Época [240/100], Loss: 0.5601\n","Época [250/100], Loss: 0.5592\n","Época [260/100], Loss: 0.5583\n","Época [270/100], Loss: 0.5574\n","Época [280/100], Loss: 0.5566\n","Época [290/100], Loss: 0.5557\n","Época [300/100], Loss: 0.5549\n","Época [310/100], Loss: 0.5542\n","Época [320/100], Loss: 0.5534\n","Época [330/100], Loss: 0.5526\n","Época [340/100], Loss: 0.5519\n","Época [350/100], Loss: 0.5512\n","Época [360/100], Loss: 0.5505\n","Época [370/100], Loss: 0.5498\n","Época [380/100], Loss: 0.5492\n","Época [390/100], Loss: 0.5485\n","Época [400/100], Loss: 0.5479\n","Época [410/100], Loss: 0.5473\n","Época [420/100], Loss: 0.5467\n","Época [430/100], Loss: 0.5461\n","Época [440/100], Loss: 0.5455\n","Época [450/100], Loss: 0.5450\n","Época [460/100], Loss: 0.5444\n","Época [470/100], Loss: 0.5439\n","Época [480/100], Loss: 0.5434\n","Época [490/100], Loss: 0.5428\n","Época [500/100], Loss: 0.5423\n","Época [510/100], Loss: 0.5419\n","Época [520/100], Loss: 0.5414\n","Época [530/100], Loss: 0.5409\n","Época [540/100], Loss: 0.5404\n","Época [550/100], Loss: 0.5400\n","Época [560/100], Loss: 0.5395\n","Época [570/100], Loss: 0.5391\n","Época [580/100], Loss: 0.5387\n","Época [590/100], Loss: 0.5383\n","Época [600/100], Loss: 0.5379\n","Época [610/100], Loss: 0.5375\n","Época [620/100], Loss: 0.5371\n","Época [630/100], Loss: 0.5367\n","Época [640/100], Loss: 0.5363\n","Época [650/100], Loss: 0.5359\n","Época [660/100], Loss: 0.5356\n","Época [670/100], Loss: 0.5352\n","Época [680/100], Loss: 0.5349\n","Época [690/100], Loss: 0.5345\n","Época [700/100], Loss: 0.5342\n","Época [710/100], Loss: 0.5339\n","Época [720/100], Loss: 0.5336\n","Época [730/100], Loss: 0.5332\n","Época [740/100], Loss: 0.5329\n","Época [750/100], Loss: 0.5326\n","Época [760/100], Loss: 0.5323\n","Época [770/100], Loss: 0.5320\n","Época [780/100], Loss: 0.5317\n","Época [790/100], Loss: 0.5314\n","Época [800/100], Loss: 0.5312\n","Época [810/100], Loss: 0.5309\n","Época [820/100], Loss: 0.5306\n","Época [830/100], Loss: 0.5303\n","Época [840/100], Loss: 0.5301\n","Época [850/100], Loss: 0.5298\n","Época [860/100], Loss: 0.5296\n","Época [870/100], Loss: 0.5293\n","Época [880/100], Loss: 0.5291\n","Época [890/100], Loss: 0.5288\n","Época [900/100], Loss: 0.5286\n","Época [910/100], Loss: 0.5284\n","Época [920/100], Loss: 0.5281\n","Época [930/100], Loss: 0.5279\n","Época [940/100], Loss: 0.5277\n","Época [950/100], Loss: 0.5275\n","Época [960/100], Loss: 0.5272\n","Época [970/100], Loss: 0.5270\n","Época [980/100], Loss: 0.5268\n","Época [990/100], Loss: 0.5266\n","Época [1000/100], Loss: 0.5264\n"]}],"source":["import torch\n","import sklearn\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# 1. Carregar dados - treinamento\n","iris = sklearn.datasets.load_iris()\n","X = iris.data        # 4 features: sépalas e pétalas\n","y = (iris.target == 1).astype(float)  # 1 se Versicolor, 0 caso contrário\n","\n","# 2. Dividir os dados em 80 amostras para treinamento e 70 para teste\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# 3. Preparar dados para pytorch - treinamento\n","X_train = torch.tensor(X_train, dtype=torch.float32)\n","y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n","\n","X_test = torch.tensor(X_test, dtype=torch.float32)\n","y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n","\n","# 4. Definir modelo: regressão logística\n","modelo = torch.nn.Linear(4, 1)  # 4 features → 1 saída (probabilidade de ser Versicolor)\n","\n","# 5. Definir função de perda e algoritmo de otimização - treinamento\n","funcao_perda = torch.nn.BCEWithLogitsLoss()  # combinação de sigmoid + BCE\n","optimizer = torch.optim.SGD(modelo.parameters(), lr=0.1)\n","\n","# 6. Treinamento\n","for epoch in range(1000):\n","    optimizer.zero_grad()  # Zera gradientes acumulados\n","    outputs = modelo(X_train)  # Passa os dados de treinamento pelo modelo\n","    loss = funcao_perda(outputs, y_train)  # Calcula a perda\n","    loss.backward()  # Calcula os gradientes (backpropagation)\n","    optimizer.step()  # Atualiza os parâmetros\n","    if (epoch + 1) % 10 == 0:\n","        print(f\"Época [{epoch+1}/100], Loss: {loss.item():.4f}\")\n","\n","\n"]},{"cell_type":"code","source":["with torch.no_grad():  # Desabilita o cálculo de gradientes\n","    outputs_test = modelo(X_test)  # Predições brutas (logits)\n","    predicoes = torch.sigmoid(outputs_test)  # Aplica sigmoid para obter probabilidades\n","    predicoes_classificadas = (predicoes > 0.5).float()  # Classifica como 0 ou 1 com base em 0.5\n","\n","# 8. Calcular acurácia\n","acuracia = accuracy_score(y_test, predicoes_classificadas)\n","print(f'Acurácia no conjunto de teste: {acuracia:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cOr5tyqXZR_s","executionInfo":{"status":"ok","timestamp":1761783857689,"user_tz":180,"elapsed":44,"user":{"displayName":"Ana Julia Alves","userId":"11391275543141261359"}},"outputId":"ef162f2c-8544-4f01-96e2-fd7b9f3f9e3e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Acurácia no conjunto de teste: 0.7667\n"]}]}]}